{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, element\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = 56\n",
    "rec_count = 0\n",
    "rank = []\n",
    "gname = []\n",
    "platform = []\n",
    "year = []\n",
    "genre = []\n",
    "critic_score = []\n",
    "user_score = []\n",
    "publisher = []\n",
    "developer = []\n",
    "sales_na = []\n",
    "sales_pal = []\n",
    "sales_jp = []\n",
    "sales_ot = []\n",
    "sales_gl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlhead = 'http://www.vgchartz.com/gamedb/?page='\n",
    "urltail = '&console=&region=All&developer=&publisher=&genre=&boxart=Both&ownership=Both'\n",
    "urltail += '&results=1000&order=Sales&showtotalsales=0&showtotalsales=1&showpublisher=0'\n",
    "urltail += '&showpublisher=1&showvgchartzscore=0&shownasales=1&showdeveloper=1&showcriticscore=1'\n",
    "urltail += '&showpalsales=0&showpalsales=1&showreleasedate=1&showuserscore=1&showjapansales=1'\n",
    "urltail += '&showlastupdate=0&showothersales=1&showgenre=1&sort=GL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for page in range(1, pages):\n",
    "    surl = urlhead + str(page) + urltail\n",
    "    r = urllib.request.urlopen(surl).read()\n",
    "    soup = BeautifulSoup(r)\n",
    "    print(f\"Page: {page}\")\n",
    "\n",
    "    # vgchartz website is really weird so we have to search for\n",
    "    # <a> tags with game urls\n",
    "    game_tags = list(filter(\n",
    "        lambda x: x.attrs['href'].startswith('http://www.vgchartz.com/game/'),\n",
    "        # discard the first 10 elements because those\n",
    "        # links are in the navigation bar\n",
    "        soup.find_all(\"a\")\n",
    "    ))[10:]\n",
    "\n",
    "    for tag in game_tags:\n",
    "\n",
    "        # add name to list\n",
    "        gname.append(\" \".join(tag.string.split()))\n",
    "        print(f\"{rec_count + 1} Fetch data for game {gname[-1]}\")\n",
    "\n",
    "        # get different attributes\n",
    "        # traverse up the DOM tree\n",
    "        data = tag.parent.parent.find_all(\"td\")\n",
    "        rank.append(np.int32(data[0].string))\n",
    "        platform.append(data[3].find('img').attrs['alt'])\n",
    "        publisher.append(data[4].string)\n",
    "        developer.append(data[5].string)\n",
    "        critic_score.append(\n",
    "            float(data[6].string) if\n",
    "            not data[6].string.startswith(\"N/A\") else np.nan)\n",
    "        user_score.append(\n",
    "            float(data[7].string) if\n",
    "            not data[7].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_na.append(\n",
    "            float(data[9].string[:-1]) if\n",
    "            not data[9].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_pal.append(\n",
    "            float(data[10].string[:-1]) if\n",
    "            not data[10].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_jp.append(\n",
    "            float(data[11].string[:-1]) if\n",
    "            not data[11].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_ot.append(\n",
    "            float(data[12].string[:-1]) if\n",
    "            not data[12].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_gl.append(\n",
    "            float(data[8].string[:-1]) if\n",
    "            not data[8].string.startswith(\"N/A\") else np.nan)\n",
    "        release_year = data[13].string.split()[-1]\n",
    "        # different format for year\n",
    "        if release_year.startswith('N/A'):\n",
    "            year.append('N/A')\n",
    "        else:\n",
    "            if int(release_year) >= 80:\n",
    "                year_to_add = np.int32(\"19\" + release_year)\n",
    "            else:\n",
    "                year_to_add = np.int32(\"20\" + release_year)\n",
    "            year.append(year_to_add)\n",
    "\n",
    "        # go to every individual website to get genre info\n",
    "        url_to_game = tag.attrs['href']\n",
    "        site_raw = urllib.request.urlopen(url_to_game).read()\n",
    "        sub_soup = BeautifulSoup(site_raw, \"html.parser\")\n",
    "        # again, the info box is inconsistent among games so we\n",
    "        # have to find all the h2 and traverse from that to the genre name\n",
    "        h2s = sub_soup.find(\"div\", {\"id\": \"gameGenInfoBox\"}).find_all('h2')\n",
    "        # make a temporary tag here to search for the one that contains\n",
    "        # the word \"Genre\"\n",
    "        temp_tag = element.Tag\n",
    "        for h2 in h2s:\n",
    "            if h2.string == 'Genre':\n",
    "                temp_tag = h2\n",
    "        genre.append(temp_tag.next_sibling.string)\n",
    "\n",
    "        rec_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    'Rank': rank,\n",
    "    'Name': gname,\n",
    "    'Platform': platform,\n",
    "    'Year': year,\n",
    "    'Genre': genre,\n",
    "    'Critic_Score': critic_score,\n",
    "    'User_Score': user_score,\n",
    "    'Publisher': publisher,\n",
    "    'Developer': developer,\n",
    "    'NA_Sales': sales_na,\n",
    "    'PAL_Sales': sales_pal,\n",
    "    'JP_Sales': sales_jp,\n",
    "    'Other_Sales': sales_ot,\n",
    "    'Global_Sales': sales_gl\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rec_count)\n",
    "df = pd.DataFrame(columns)\n",
    "print(df.columns)\n",
    "df = df[[\n",
    "    'Rank', 'Name', 'Platform', 'Year', 'Genre',\n",
    "    'Publisher', 'Developer', 'Critic_Score', 'User_Score',\n",
    "    'NA_Sales', 'PAL_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']]\n",
    "df.to_csv(\"vgsales.csv\", sep=\",\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "RemoteDisconnected",
     "evalue": "Remote end closed connection without response",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-b3dccb39f6c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgenre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0murl_to_game\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"http://www.vgchartz.com/game/45608/kinect-adventures/?region=All\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msite_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_to_game\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msub_soup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msite_raw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# again, the info box is inconsistent among games so we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 543\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1320\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m             \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[1;31m# Presumably, the server closed the connection before\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[1;31m# sending a valid response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m             raise RemoteDisconnected(\"Remote end closed connection without\"\n\u001b[0m\u001b[0;32m    266\u001b[0m                                      \" response\")\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response"
     ]
    }
   ],
   "source": [
    "rating = []\n",
    "genre = []\n",
    "url_to_game = \"http://www.vgchartz.com/game/45608/kinect-adventures/?region=All\"\n",
    "site_raw = urllib.request.urlopen(url_to_game).read()\n",
    "sub_soup = BeautifulSoup(site_raw, \"lxml\")\n",
    "# again, the info box is inconsistent among games so we\n",
    "# have to find all the h2 and traverse from that to the genre name\n",
    "gamebox = sub_soup.find(\"div\", {\"id\": \"gameGenInfoBox\"})\n",
    "h2s = gamebox.find_all('h2')\n",
    "# make a temporary tag here to search for the one that contains\n",
    "# the word \"Genre\"\n",
    "temp_tag = element.Tag\n",
    "for h2 in h2s:\n",
    "    if h2.string == 'Genre':\n",
    "        temp_tag = h2\n",
    "genre.append(temp_tag.next_sibling.string)\n",
    "\n",
    "#find the ESRB rating\n",
    "game_rating = gamebox.find('img').get('src')\n",
    "if 'esrb' in game_rating:\n",
    "    rating.append(game_rating[game_rating.index('esrb'):])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "links = sub_soup.find_all('img')\n",
    "for i in sub_soup.find_all('img'):\n",
    "    rate = i.get('src')\n",
    "    try:\n",
    "        if 'ESRB' in rate:\n",
    "            rating.append(rate[rate.index('esrb'):])\n",
    "            break\n",
    "    except:\n",
    "        pass\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'getcode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-444cb86dc52f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_to_game\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'getcode'"
     ]
    }
   ],
   "source": [
    "urllib.request.urlopen(url_to_game).read().getcode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for h2 in h2s:\n",
    "    if h2.string == 'Ratings':\n",
    "        temp_tag1 = h2\n",
    "    if h2.string == 'Genre':\n",
    "        temp_tag = h2\n",
    "genre.append(temp_tag.next_sibling.string)\n",
    "rating.append(temp_tag1.nextSibling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['esrb/ESRB_e.png']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Racing']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #go to game page to parse genre and rating\n",
    "        try:\n",
    "            site_raw = urllib.request.urlopen(game[\"url\"]).read()\n",
    "            sub_soup = BeautifulSoup(site_raw, \"lxml\")\n",
    "            # again, the info box is inconsistent among games so we\n",
    "            # have to find all the h2 and traverse from that to the genre name\n",
    "            gamebox = sub_soup.find(\"div\", {\"id\": \"gameGenInfoBox\"})\n",
    "            h2s = gamebox.find_all('h2')\n",
    "            # make a temporary tag here to search for the one that contains\n",
    "            # the word \"Genre\"\n",
    "            temp_tag = element.Tag\n",
    "            for h2 in h2s:\n",
    "                if h2.string == 'Genre':\n",
    "                    temp_tag = h2\n",
    "            game[\"genre\"] = temp_tag.next_sibling.string\n",
    "\n",
    "            #find the ESRB rating\n",
    "            game_rating = gamebox.find('img').get('src')\n",
    "            if 'esrb' in game_rating:\n",
    "                game[\"vg_rating\"] = game_rating[game_rating.index('esrb'):]\n",
    "        except: \n",
    "            game[\"genre\"] = 'N/A'\n",
    "            game[\"vg_rating\"] = 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from user_agent import generate_user_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        try:\n",
    "            #site_raw = urllib.request.urlopen(url_to_game).read()\n",
    "            site_row = requests.get(url_to_game, headers={\n",
    "                                    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv: 12.0) Gecko/20100101 Firefox/12.0'}).text\n",
    "            sub_soup = BeautifulSoup(site_raw, \"lxml\")\n",
    "            # again, the info box is inconsistent among games so we\n",
    "            # have to find all the h2 and traverse from that to the genre name\n",
    "            gamebox = sub_soup.find(\"div\", {\"id\": \"gameGenInfoBox\"})\n",
    "            h2s = gamebox.find_all('h2')\n",
    "            # make a temporary tag here to search for the one that contains\n",
    "            # the word \"Genre\"\n",
    "            temp_tag = element.Tag\n",
    "            for h2 in h2s:\n",
    "                if h2.string == 'Genre':\n",
    "                    temp_tag = h2\n",
    "            genre.append(temp_tag.next_sibling.string)\n",
    "            #find the ESRB rating\n",
    "            game_rating = gamebox.find('img').get('src')\n",
    "            if 'esrb' in game_rating:\n",
    "                rating.append(game_rating[game_rating.index('esrb'):])\n",
    "        except:\n",
    "            print('something wrong with game url:', url_to_game)\n",
    "            genre.append(np.nan)\n",
    "            rating.append(np.nan)\n",
    "\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'103.84.254.190:56505'}\n"
     ]
    }
   ],
   "source": [
    "from lxml.html import fromstring\n",
    "import requests\n",
    "from itertools import cycle\n",
    "import traceback\n",
    "\n",
    "def get_proxies():\n",
    "    url = 'https://free-proxy-list.net/'\n",
    "    response = requests.get(url)\n",
    "    parser = fromstring(response.text)\n",
    "    proxies = set()\n",
    "    for i in parser.xpath('//tbody/tr')[:20]:\n",
    "        if i.xpath('.//td[7][contains(text(),\"yes\")]'):\n",
    "            proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
    "            proxies.add(proxy)\n",
    "    return proxies\n",
    "\n",
    "\n",
    "#If you are copy pasting proxy ips, put in the list below\n",
    "#proxies = ['121.129.127.209:80', '124.41.215.238:45169', '185.93.3.123:8080', '194.182.64.67:3128', '106.0.38.174:8080', '163.172.175.210:3128', '13.92.196.150:8080']\n",
    "proxies = get_proxies()\n",
    "proxy_pool = cycle(proxies)\n",
    "print(proxies)\n",
    "\n",
    "url = 'https://httpbin.org/ip'\n",
    "for i in range(1,len(proxies)):\n",
    "    #Get a proxy from the pool\n",
    "    proxy = next(proxy_pool)\n",
    "    print(\"Request #%d\"%i)\n",
    "    try:\n",
    "        response = requests.get(url,proxies={\"http\": proxy, \"https\": proxy})\n",
    "        print(response.json())\n",
    "    except:\n",
    "        #Most free proxies will often get connection errors. You will have retry the entire request using another proxy to work. \n",
    "        #We will just skip retries as its beyond the scope of this tutorial and we are only downloading a single url \n",
    "        print(\"Skipping. Connnection error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.vgchartz.com/games/games.php?page=280&results=200&name=&console=&keyword=&publisher=&genre=&order=Sales&ownership=Both&boxart=Both&banner=Both&showdeleted=&region=All&goty_year=&developer=&direction=DESC&showtotalsales=0&shownasales=0&showpalsales=0&showjapansales=0&showothersales=0&showpublisher=1&showdeveloper=0&showreleasedate=1&showlastupdate=1&showvgchartzscore=1&showcriticscore=1&showuserscore=1&showshipped=1&alphasort=&showmultiplat=No\"\n",
    "page = requests.get(url).text\n",
    "x = fromstring(page).xpath(\"//th[@colspan='3']/text()\")[0].split('(', 1)[1].split(')')[0]\n",
    "np.ceil(int(x.replace(',',\"\"))/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
